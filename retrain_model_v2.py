"""
FCN Model Retraining Script V2
==============================
- ä½¿ç”¨æœ€æ–°çš„ FCNè³‡æ–™è¡¨.xlsx (åŒ…å« 2025/12/12 æ–°è³‡æ–™)
- å„ªåŒ–é«˜ IV è‚¡ç¥¨é æ¸¬ (IV > 80)
- æ”¯æ´ Non-call Periods ç‰¹å¾µ
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import HistGradientBoostingRegressor
import joblib
import warnings
import os
warnings.filterwarnings('ignore')

print("=" * 80)
print("FCN æ¨¡å‹é‡æ–°è¨“ç·´ V2")
print("=" * 80)

# ============================================================================
# 1. è¼‰å…¥ä¸¦åˆä½µè³‡æ–™
# ============================================================================
print("\n" + "=" * 80)
print("1. è¼‰å…¥è³‡æ–™")
print("=" * 80)

# è¼‰å…¥ FCN è³‡æ–™è¡¨
df_fcn = pd.read_excel('FCNè³‡æ–™è¡¨.xlsx')
print(f"FCN è³‡æ–™è¡¨: {df_fcn.shape}")

# æª¢æŸ¥æ–°è³‡æ–™
new_data_count = df_fcn['Pricing Date'].astype(str).str.contains('2025-12-12|2025/12/12|20251212', na=False).sum()
print(f"2025/12/12 æ–°è³‡æ–™: {new_data_count} ç­†")

# é¡¯ç¤º Non-call åˆ†ä½ˆ
print(f"\nã€Non-call Periods åˆ†ä½ˆã€‘")
print(df_fcn['Non-call Periods (m)'].value_counts().head(10))

# ============================================================================
# 2. è¼‰å…¥ IV è³‡æ–™ä¸¦åˆä½µ
# ============================================================================
print("\n" + "=" * 80)
print("2. è¼‰å…¥ IV è³‡æ–™")
print("=" * 80)

# æ‰¾åˆ°æ‰€æœ‰ IV è³‡æ–™æª”æ¡ˆ
iv_data_path = 'iv_data'
if not os.path.exists(iv_data_path):
    iv_data_path = 'fcn-web-app/backend/data/iv_data'

iv_files = [f for f in os.listdir(iv_data_path) if f.endswith('.xlsx') and not f.startswith('~$')]
print(f"æ‰¾åˆ° {len(iv_files)} å€‹ IV è³‡æ–™æª”æ¡ˆ")

# è¼‰å…¥æ‰€æœ‰ IV è³‡æ–™
all_iv_data = {}
for iv_file in iv_files:
    date_key = iv_file.replace('.xlsx', '')
    df_iv = pd.read_excel(os.path.join(iv_data_path, iv_file))
    # è·³éæ¨™é¡Œè¡Œ
    df_iv = df_iv.iloc[1:].reset_index(drop=True)
    df_iv = df_iv.rename(columns={'Unnamed: 0': 'BBG_Code'})
    # æ¸…ç†ä»£ç¢¼
    df_iv['BBG_Code'] = df_iv['BBG_Code'].astype(str).str.replace(' Equity', '', regex=False)
    df_iv['BBG_Code'] = df_iv['BBG_Code'].str.replace(' US', '', regex=False)
    all_iv_data[date_key] = df_iv

print(f"å·²è¼‰å…¥ IV è³‡æ–™æ—¥æœŸ: {list(all_iv_data.keys())}")

# ============================================================================
# 3. è³‡æ–™åˆä½µèˆ‡å‰è™•ç†
# ============================================================================
print("\n" + "=" * 80)
print("3. è³‡æ–™åˆä½µèˆ‡å‰è™•ç†")
print("=" * 80)

# æ¸…ç† FCN è³‡æ–™
df = df_fcn.copy()

# ç§»é™¤ä¸éœ€è¦çš„æ¬„ä½
cols_to_drop = ['Unnamed: 17', 'BBG Code 4', 'BBG Code 5']
existing_cols_to_drop = [col for col in cols_to_drop if col in df.columns]
if existing_cols_to_drop:
    df = df.drop(existing_cols_to_drop, axis=1)

# è™•ç† Coupon æ¬„ä½
df['Coupon_Valid'] = (df['Coupon p.a. (%)'] != '-')
df['Coupon'] = df['Coupon p.a. (%)'].apply(lambda x: float(x) if x != '-' else np.nan)

# åªä¿ç•™æœ‰æ•ˆ Coupon
df = df[df['Coupon_Valid']].copy()
print(f"æœ‰æ•ˆ Coupon è³‡æ–™: {len(df)} ç­†")

# æ¨™çš„æ•¸é‡
df['Num_Underlyings'] = (
    df['BBG Code 1'].notna().astype(int) +
    df['BBG Code 2'].notna().astype(int) +
    df['BBG Code 3'].notna().astype(int)
)

# è½‰æ› Pricing Date æ ¼å¼ä»¥ä¾¿åŒ¹é… IV è³‡æ–™
def get_date_key(date_val):
    """å°‡æ—¥æœŸè½‰æ›ç‚º YYYYMMDD æ ¼å¼"""
    try:
        if pd.isna(date_val):
            return None
        if isinstance(date_val, str):
            # å˜—è©¦ä¸åŒæ ¼å¼
            for fmt in ['%Y-%m-%d', '%Y/%m/%d', '%m/%d/%Y']:
                try:
                    return pd.to_datetime(date_val, format=fmt).strftime('%Y%m%d')
                except:
                    continue
        return pd.to_datetime(date_val).strftime('%Y%m%d')
    except:
        return None

df['Date_Key'] = df['Pricing Date'].apply(get_date_key)

# ç‚ºæ¯å€‹æ¨™çš„åˆä½µ IV è³‡æ–™
print("\nåˆä½µ IV è³‡æ–™...")

iv_columns = ['PX_LAST', '3MO_PUT_IMP_VOL', '2M_CALL_IMP_VOL_25DELTA_DFLT',
              '2M_PUT_IMP_VOL_25DELTA_DFLT', 'HIST_PUT_IMP_VOL', 'VOL_STDDEV',
              'VOLATILITY_90D', 'VOL_PERCENTILE', 'CHG_PCT_1YR', 'CORR_COEF',
              'DIVIDEND_INDICATED_YIELD']

iv_rename = {
    '3MO_PUT_IMP_VOL': 'PUT_IMP_VOL_3M',
    '2M_CALL_IMP_VOL_25DELTA_DFLT': 'CALL_IMP_VOL_2M_25D',
    '2M_PUT_IMP_VOL_25DELTA_DFLT': 'PUT_IMP_VOL_2M_25D',
    'DIVIDEND_INDICATED_YIELD': 'DIVIDEND_YIELD'
}

def get_iv_for_stock(row, stock_col, suffix=''):
    """å–å¾—ç‰¹å®šè‚¡ç¥¨çš„ IV è³‡æ–™"""
    date_key = row.get('Date_Key')
    stock_code = row.get(stock_col)

    if pd.isna(date_key) or pd.isna(stock_code):
        return pd.Series({f'{iv_rename.get(col, col)}{suffix}': np.nan for col in iv_columns})

    # æ¸…ç†è‚¡ç¥¨ä»£ç¢¼
    stock_code = str(stock_code).replace(' Equity', '').replace(' US', '').strip()

    # æŸ¥æ‰¾ IV è³‡æ–™
    iv_df = all_iv_data.get(date_key)
    if iv_df is None:
        # æ‰¾æœ€è¿‘çš„æ—¥æœŸ
        available_dates = sorted(all_iv_data.keys(), reverse=True)
        for d in available_dates:
            if d <= date_key:
                iv_df = all_iv_data[d]
                break
        if iv_df is None and available_dates:
            iv_df = all_iv_data[available_dates[0]]

    if iv_df is None:
        return pd.Series({f'{iv_rename.get(col, col)}{suffix}': np.nan for col in iv_columns})

    # æŸ¥æ‰¾è‚¡ç¥¨
    stock_row = iv_df[iv_df['BBG_Code'] == stock_code]
    if len(stock_row) == 0:
        return pd.Series({f'{iv_rename.get(col, col)}{suffix}': np.nan for col in iv_columns})

    result = {}
    for col in iv_columns:
        new_col = f'{iv_rename.get(col, col)}{suffix}'
        if col in stock_row.columns:
            val = stock_row.iloc[0][col]
            try:
                result[new_col] = float(val) if pd.notna(val) else np.nan
            except:
                result[new_col] = np.nan
        else:
            result[new_col] = np.nan

    return pd.Series(result)

# åˆä½µ BBG Code 1 çš„ IV
print("  è™•ç† BBG Code 1...")
iv_1 = df.apply(lambda row: get_iv_for_stock(row, 'BBG Code 1', ''), axis=1)
df = pd.concat([df, iv_1], axis=1)

# åˆä½µ BBG Code 2 çš„ IV
print("  è™•ç† BBG Code 2...")
iv_2 = df.apply(lambda row: get_iv_for_stock(row, 'BBG Code 2', '_2'), axis=1)
df = pd.concat([df, iv_2], axis=1)

# åˆä½µ BBG Code 3 çš„ IV
print("  è™•ç† BBG Code 3...")
iv_3 = df.apply(lambda row: get_iv_for_stock(row, 'BBG Code 3', '_3'), axis=1)
df = pd.concat([df, iv_3], axis=1)

print(f"åˆä½µå¾Œè³‡æ–™å½¢ç‹€: {df.shape}")

# ============================================================================
# 4. ç‰¹å¾µå·¥ç¨‹
# ============================================================================
print("\n" + "=" * 80)
print("4. ç‰¹å¾µå·¥ç¨‹")
print("=" * 80)

# 4.1 è²»ç”¨ç‰¹å¾µ
df['Fee'] = 100 - df['Cost (%)']
df['Annualized_Fee'] = (df['Fee'] / df['Tenor (m)']) * 12

# 4.2 éšœç¤™åƒ¹ç‰¹å¾µ
df['KO_Strike_Distance'] = df['KO Barrier (%)'] - df['Strike (%)']
df['Strike_KI_Distance'] = df['Strike (%)'] - df['KI Barrier (%)']
df['KO_KI_Range'] = df['KO Barrier (%)'] - df['KI Barrier (%)']
df['KI_Strike_Ratio'] = df['KI Barrier (%)'] / df['Strike (%)']
df['KO_Strike_Ratio'] = df['KO Barrier (%)'] / df['Strike (%)']
df['KI_Distance_Pct'] = df['Strike (%)'] - df['KI Barrier (%)']
df['KO_Distance_Pct'] = df['KO Barrier (%)'] - df['Strike (%)']

# 4.3 æ™‚é–“åƒ¹å€¼ç‰¹å¾µ
df['Tenor_Sqrt'] = np.sqrt(df['Tenor (m)'])
df['Tenor_Squared'] = df['Tenor (m)'] ** 2
df['Callable_Period'] = df['Tenor (m)'] - df['Non-call Periods (m)']
df['Callable_Ratio'] = df['Callable_Period'] / df['Tenor (m)']
df['NonCall_Ratio'] = df['Non-call Periods (m)'] / df['Tenor (m)']

# 4.4 Non-call == Tenor ç‰¹å¾µ (ä¸æœƒ KO çš„æƒ…æ³)
df['No_KO_Flag'] = (df['Non-call Periods (m)'] == df['Tenor (m)']).astype(int)

# 4.5 Basket ç‰¹å¾µ
df['Basket_Size'] = df['Num_Underlyings']

# Worst/Best IV
df['Basket_Worst_IV'] = df[['PUT_IMP_VOL_3M', 'PUT_IMP_VOL_3M_2', 'PUT_IMP_VOL_3M_3']].max(axis=1, skipna=True)
df['Basket_Best_IV'] = df[['PUT_IMP_VOL_3M', 'PUT_IMP_VOL_3M_2', 'PUT_IMP_VOL_3M_3']].min(axis=1, skipna=True)
df['Basket_IV_Range'] = df['Basket_Worst_IV'] - df['Basket_Best_IV']

# å¹³å‡ IV
def safe_mean(row, cols):
    values = [row[col] for col in cols if col in row.index and pd.notna(row[col])]
    return np.mean(values) if values else np.nan

iv_3m_cols = ['PUT_IMP_VOL_3M', 'PUT_IMP_VOL_3M_2', 'PUT_IMP_VOL_3M_3']
hv_90d_cols = ['VOLATILITY_90D', 'VOLATILITY_90D_2', 'VOLATILITY_90D_3']
corr_cols = ['CORR_COEF', 'CORR_COEF_2', 'CORR_COEF_3']

df['Basket_Avg_IV'] = df.apply(lambda row: safe_mean(row, iv_3m_cols), axis=1)
df['Basket_Avg_HV'] = df.apply(lambda row: safe_mean(row, hv_90d_cols), axis=1)
df['Basket_Avg_Corr'] = df.apply(lambda row: safe_mean(row, corr_cols), axis=1)

# æ­·å²æ³¢å‹•ç‡
df['Basket_Worst_HV'] = df[['VOLATILITY_90D', 'VOLATILITY_90D_2', 'VOLATILITY_90D_3']].max(axis=1, skipna=True)
df['Basket_Best_HV'] = df[['VOLATILITY_90D', 'VOLATILITY_90D_2', 'VOLATILITY_90D_3']].min(axis=1, skipna=True)

# ç›¸é—œæ€§
df['Basket_Min_Corr'] = df[['CORR_COEF', 'CORR_COEF_2', 'CORR_COEF_3']].min(axis=1, skipna=True)
df['Max_Correlation'] = df[['CORR_COEF', 'CORR_COEF_2', 'CORR_COEF_3']].max(axis=1, skipna=True)
df['Min_Correlation'] = df['Basket_Min_Corr']

# Basket è¤‡é›œåº¦
df['Basket_Complexity_Factor'] = df['Basket_Size'] / 3.0

# ç›¸é—œæ€§èª¿æ•´ IV
df['Corr_Adjusted_IV'] = df['Basket_Worst_IV'].copy()
multi_asset_mask = (df['Basket_Size'] > 1) & (df['Basket_Avg_Corr'].notna())
df.loc[multi_asset_mask, 'Corr_Adjusted_IV'] = (
    df.loc[multi_asset_mask, 'Basket_Worst_IV'] *
    (1 + 0.1 * (df.loc[multi_asset_mask, 'Basket_Size'] - 1) *
     (1 - df.loc[multi_asset_mask, 'Basket_Avg_Corr']))
)

# 4.6 IV Skew å’Œ Premium
df['IV_Skew_1'] = df['PUT_IMP_VOL_2M_25D'] - df['CALL_IMP_VOL_2M_25D']
df['IV_Skew_2'] = df['PUT_IMP_VOL_2M_25D_2'] - df['CALL_IMP_VOL_2M_25D_2']
df['IV_Skew_3'] = df['PUT_IMP_VOL_2M_25D_3'] - df['CALL_IMP_VOL_2M_25D_3']

skew_cols = ['IV_Skew_1', 'IV_Skew_2', 'IV_Skew_3']
df['Basket_Avg_Skew'] = df.apply(lambda row: safe_mean(row, skew_cols), axis=1)
df['Basket_Max_Skew'] = df[skew_cols].max(axis=1, skipna=True)

df['IV_Premium_1'] = (df['PUT_IMP_VOL_3M'] - df['VOLATILITY_90D']) / df['VOLATILITY_90D']
df['IV_Premium_2'] = (df['PUT_IMP_VOL_3M_2'] - df['VOLATILITY_90D_2']) / df['VOLATILITY_90D_2']
df['IV_Premium_3'] = (df['PUT_IMP_VOL_3M_3'] - df['VOLATILITY_90D_3']) / df['VOLATILITY_90D_3']

premium_cols = ['IV_Premium_1', 'IV_Premium_2', 'IV_Premium_3']
df['Basket_Avg_IV_Premium'] = df.apply(lambda row: safe_mean(row, premium_cols), axis=1)
df['Basket_Max_IV_Premium'] = df[premium_cols].max(axis=1, skipna=True)

# 4.7 æ¨™æº–åŒ–è·é›¢
df['Annualized_Vol_Factor'] = df['Basket_Worst_IV'] / 100 * np.sqrt(df['Tenor (m)'] / 12)
df['KI_Distance_Std'] = df['KI_Distance_Pct'] / 100 / df['Annualized_Vol_Factor']
df['KO_Distance_Std'] = df['KO_Distance_Pct'] / 100 / df['Annualized_Vol_Factor']

# 4.8 IV æ¯”ç‡
df['IV_HV_Ratio'] = df['Basket_Avg_IV'] / df['Basket_Avg_HV']

# 4.9 é¢¨éšªè©•åˆ†
df['KI_Risk_Score'] = (df['Basket_Worst_IV'] / df['Basket_Worst_IV'].mean()) * (df['KI Barrier (%)'] / 100)
df['Return_Potential'] = (df['KO Barrier (%)'] / 100) * (df['Tenor (m)'] / 12)

df['Basket_Risk_Score'] = (
    (df['Basket_Worst_IV'] / df['Basket_Worst_IV'].mean()) *
    (df['KI Barrier (%)'] / 100) *
    (1 + 0.2 * (df['Basket_Size'] - 1))
)
df.loc[multi_asset_mask, 'Basket_Risk_Score'] = (
    df.loc[multi_asset_mask, 'Basket_Risk_Score'] *
    (1 + 0.1 * (1 - df.loc[multi_asset_mask, 'Basket_Avg_Corr']))
)

# 4.10 Barrier Type ç·¨ç¢¼
df['Barrier_Type_AKI'] = (df['Barrier Type'] == 'AKI').astype(int)

# 4.11 å¹´åŒ–æ³¢å‹•ç‡
df['Annualized_Vol'] = df['Basket_Avg_IV'] * np.sqrt(df['Tenor (m)'] / 12)

# 4.12 IV æ’åºç‰¹å¾µ (æŒ‰ PUT_IMP_VOL_3M é™å†ªæ’åº)
print("\nå»ºç«‹ IV æ’åºç‰¹å¾µ...")

def get_iv_sort_indices(row):
    iv_values = [
        (0, row['PUT_IMP_VOL_3M'] if pd.notna(row.get('PUT_IMP_VOL_3M')) else -np.inf),
        (1, row.get('PUT_IMP_VOL_3M_2', np.nan) if pd.notna(row.get('PUT_IMP_VOL_3M_2')) else -np.inf),
        (2, row.get('PUT_IMP_VOL_3M_3', np.nan) if pd.notna(row.get('PUT_IMP_VOL_3M_3')) else -np.inf),
    ]
    sorted_indices = sorted(iv_values, key=lambda x: x[1], reverse=True)
    return [x[0] for x in sorted_indices]

sort_indices = df.apply(get_iv_sort_indices, axis=1)
df['_sort_idx_0'] = sort_indices.apply(lambda x: x[0])
df['_sort_idx_1'] = sort_indices.apply(lambda x: x[1])
df['_sort_idx_2'] = sort_indices.apply(lambda x: x[2])

# IV æ¬„ä½çµ„
iv_groups = {
    'PUT_IMP_VOL_3M': ['PUT_IMP_VOL_3M', 'PUT_IMP_VOL_3M_2', 'PUT_IMP_VOL_3M_3'],
    'VOLATILITY_90D': ['VOLATILITY_90D', 'VOLATILITY_90D_2', 'VOLATILITY_90D_3'],
    'CALL_IMP_VOL_2M_25D': ['CALL_IMP_VOL_2M_25D', 'CALL_IMP_VOL_2M_25D_2', 'CALL_IMP_VOL_2M_25D_3'],
    'PUT_IMP_VOL_2M_25D': ['PUT_IMP_VOL_2M_25D', 'PUT_IMP_VOL_2M_25D_2', 'PUT_IMP_VOL_2M_25D_3'],
    'HIST_PUT_IMP_VOL': ['HIST_PUT_IMP_VOL', 'HIST_PUT_IMP_VOL_2', 'HIST_PUT_IMP_VOL_3'],
    'VOL_STDDEV': ['VOL_STDDEV', 'VOL_STDDEV_2', 'VOL_STDDEV_3'],
    'VOL_PERCENTILE': ['VOL_PERCENTILE', 'VOL_PERCENTILE_2', 'VOL_PERCENTILE_3'],
    'CHG_PCT_1YR': ['CHG_PCT_1YR', 'CHG_PCT_1YR_2', 'CHG_PCT_1YR_3'],
    'CORR_COEF': ['CORR_COEF', 'CORR_COEF_2', 'CORR_COEF_3'],
    'DIVIDEND_YIELD': ['DIVIDEND_YIELD', 'DIVIDEND_YIELD_2', 'DIVIDEND_YIELD_3'],
    'PX_LAST': ['PX_LAST', 'PX_LAST_2', 'PX_LAST_3'],
}

for group_name, cols in iv_groups.items():
    if all(col in df.columns for col in cols[:1]):
        rank_cols = [f'{group_name}_Rank_{i+1}' for i in range(3)]
        for i, rank_col in enumerate(rank_cols):
            def get_sorted_value(row, original_cols=cols, idx_col=f'_sort_idx_{i}'):
                idx = int(row[idx_col])
                if idx < len(original_cols) and original_cols[idx] in row.index:
                    return row[original_cols[idx]]
                return np.nan
            df[rank_col] = df.apply(get_sorted_value, axis=1)

# IV Skew å’Œ Premium æ’åºç‰ˆæœ¬
for i in range(3):
    put_col = f'PUT_IMP_VOL_2M_25D_Rank_{i+1}'
    call_col = f'CALL_IMP_VOL_2M_25D_Rank_{i+1}'
    if put_col in df.columns and call_col in df.columns:
        df[f'IV_Skew_Rank_{i+1}'] = df[put_col] - df[call_col]

    iv_col = f'PUT_IMP_VOL_3M_Rank_{i+1}'
    hv_col = f'VOLATILITY_90D_Rank_{i+1}'
    if iv_col in df.columns and hv_col in df.columns:
        df[f'IV_Premium_Rank_{i+1}'] = (df[iv_col] - df[hv_col]) / df[hv_col]

# æ’åºå¾Œçš„é¢¨éšªç‰¹å¾µ
df['KI_Distance_Std_Sorted'] = (
    (df['Strike (%)'] - df['KI Barrier (%)']) / 100 /
    (df['PUT_IMP_VOL_3M_Rank_1'] / 100 * np.sqrt(df['Tenor (m)'] / 12))
)

df['Risk_Score_Sorted'] = (
    (df['PUT_IMP_VOL_3M_Rank_1'] / df['PUT_IMP_VOL_3M_Rank_1'].mean()) *
    (df['KI Barrier (%)'] / 100) *
    (1 + 0.2 * (df['Basket_Size'] - 1))
)

# ç§»é™¤è¼”åŠ©æ¬„ä½
df = df.drop(['_sort_idx_0', '_sort_idx_1', '_sort_idx_2'], axis=1)

print(f"ç‰¹å¾µå·¥ç¨‹å¾Œè³‡æ–™å½¢ç‹€: {df.shape}")

# ============================================================================
# 5. æº–å‚™è¨“ç·´è³‡æ–™
# ============================================================================
print("\n" + "=" * 80)
print("5. æº–å‚™è¨“ç·´è³‡æ–™")
print("=" * 80)

target = 'Coupon'

# æ’é™¤æ¬„ä½
exclude_cols = [
    'Coupon', 'Coupon p.a. (%)', 'Coupon_Valid',
    'Pricing Date', 'Date_Key',
    'BBG Code 1', 'BBG Code 2', 'BBG Code 3',
    'Product', 'Currency', 'KO Type', 'Barrier Type',
]

# ç²å–æ‰€æœ‰æ•¸å€¼å‹ç‰¹å¾µ
all_numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
feature_cols = [col for col in all_numeric_cols if col not in exclude_cols]

print(f"ç¸½ç‰¹å¾µæ•¸: {len(feature_cols)}")

X = df[feature_cols].copy()
y = df[target].copy()

# ç§»é™¤ NaN ç›®æ¨™å€¼
valid_mask = y.notna()
X = X[valid_mask]
y = y[valid_mask]

print(f"æœ‰æ•ˆæ¨£æœ¬æ•¸: {len(y)}")

# åˆ†æé«˜ IV æ¨£æœ¬
high_iv_mask = df.loc[valid_mask, 'Basket_Worst_IV'] > 80
print(f"é«˜ IV (>80) æ¨£æœ¬æ•¸: {high_iv_mask.sum()}")

# åˆ†å‰²è³‡æ–™
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"è¨“ç·´é›†: {len(X_train)}, æ¸¬è©¦é›†: {len(X_test)}")

# ============================================================================
# 6. è¨“ç·´æ¨¡å‹
# ============================================================================
print("\n" + "=" * 80)
print("6. è¨“ç·´æ¨¡å‹")
print("=" * 80)

# HistGradient Boosting (æ·±å±¤ç‰ˆæœ¬ï¼Œå„ªåŒ–é«˜ IV)
print("\nã€HistGradient Boosting (æ·±å±¤ + å„ªåŒ–)ã€‘")

model = HistGradientBoostingRegressor(
    max_iter=500,
    max_depth=15,
    learning_rate=0.05,
    min_samples_leaf=3,
    l2_regularization=0.1,
    random_state=42
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"  RMSE: {rmse:.4f}")
print(f"  MAE:  {mae:.4f}")
print(f"  RÂ²:   {r2:.4f}")

# é«˜ IV æ¨£æœ¬çš„è¡¨ç¾
high_iv_test_mask = X_test['Basket_Worst_IV'] > 80 if 'Basket_Worst_IV' in X_test.columns else pd.Series([False] * len(X_test))
if high_iv_test_mask.sum() > 0:
    high_iv_rmse = np.sqrt(mean_squared_error(y_test[high_iv_test_mask], y_pred[high_iv_test_mask]))
    high_iv_r2 = r2_score(y_test[high_iv_test_mask], y_pred[high_iv_test_mask])
    print(f"\né«˜ IV (>80) è¡¨ç¾:")
    print(f"  æ¨£æœ¬æ•¸: {high_iv_test_mask.sum()}")
    print(f"  RMSE: {high_iv_rmse:.4f}")
    print(f"  RÂ²:   {high_iv_r2:.4f}")

# ============================================================================
# 7. äº¤å‰é©—è­‰
# ============================================================================
print("\n" + "=" * 80)
print("7. äº¤å‰é©—è­‰ (5-Fold)")
print("=" * 80)

kfold = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(model, X, y, cv=kfold, scoring='r2', n_jobs=-1)
print(f"CV RÂ² = {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")

# ============================================================================
# 8. ç‰¹å¾µé‡è¦æ€§
# ============================================================================
print("\n" + "=" * 80)
print("8. ç‰¹å¾µé‡è¦æ€§ Top 25")
print("=" * 80)

if hasattr(model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)

    print(f"{'æ’å':<5} {'ç‰¹å¾µåç¨±':<40} {'é‡è¦æ€§':>10}")
    print("-" * 60)
    for i, row in feature_importance.head(25).iterrows():
        rank = feature_importance.index.get_loc(i) + 1
        print(f"{rank:<5} {row['feature']:<40} {row['importance']:>10.4f}")

    feature_importance.to_excel('feature_importance_v2.xlsx', index=False)

# ============================================================================
# 9. èª¤å·®åˆ†æ
# ============================================================================
print("\n" + "=" * 80)
print("9. èª¤å·®åˆ†æ")
print("=" * 80)

errors = y_test - y_pred
abs_errors = np.abs(errors)

print(f"å¹³å‡èª¤å·®: {errors.mean():.4f}")
print(f"èª¤å·®æ¨™æº–å·®: {errors.std():.4f}")
print(f"\nçµ•å°èª¤å·®åˆ†ä½ˆ:")
print(f"  < 0.5%: {(abs_errors < 0.5).sum() / len(abs_errors) * 100:.1f}%")
print(f"  < 1.0%: {(abs_errors < 1.0).sum() / len(abs_errors) * 100:.1f}%")
print(f"  < 2.0%: {(abs_errors < 2.0).sum() / len(abs_errors) * 100:.1f}%")

# ============================================================================
# 10. å„²å­˜æ¨¡å‹
# ============================================================================
print("\n" + "=" * 80)
print("10. å„²å­˜æ¨¡å‹")
print("=" * 80)

# å„²å­˜æ¨¡å‹
model_filename = 'fcn_model_v2.pkl'
joblib.dump(model, model_filename)
print(f"æ¨¡å‹å·²å„²å­˜: {model_filename}")

# å„²å­˜ç‰¹å¾µåˆ—è¡¨
with open('model_features_v2.txt', 'w') as f:
    for feat in feature_cols:
        f.write(f"{feat}\n")
print(f"ç‰¹å¾µåˆ—è¡¨å·²å„²å­˜: model_features_v2.txt")

# è¤‡è£½åˆ° web-app
import shutil
webapp_model_dir = 'fcn-web-app/backend/models'
if os.path.exists(webapp_model_dir):
    shutil.copy(model_filename, os.path.join(webapp_model_dir, 'fcn_model_histgradient_boosting_deep.pkl'))
    shutil.copy('model_features_v2.txt', os.path.join(webapp_model_dir, 'model_features.txt'))
    print(f"å·²è¤‡è£½åˆ° web-app: {webapp_model_dir}")

# ============================================================================
# 11. ç¸½çµ
# ============================================================================
print("\n" + "=" * 80)
print("11. è¨“ç·´ç¸½çµ")
print("=" * 80)

print(f"""
ğŸ“Š è³‡æ–™è¦æ¨¡:
   - ç¸½æ¨£æœ¬: {len(y)}
   - è¨“ç·´é›†: {len(X_train)}
   - æ¸¬è©¦é›†: {len(X_test)}
   - ç‰¹å¾µæ•¸: {len(feature_cols)}
   - é«˜ IV æ¨£æœ¬: {high_iv_mask.sum()}

ğŸ† æ¨¡å‹è¡¨ç¾:
   - RÂ²:   {r2:.4f}
   - RMSE: {rmse:.4f}
   - MAE:  {mae:.4f}
   - CV RÂ²: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}

ğŸ“ˆ é æ¸¬æº–ç¢ºåº¦:
   - {(abs_errors < 1.0).sum() / len(abs_errors) * 100:.1f}% èª¤å·® < 1%
   - {(abs_errors < 2.0).sum() / len(abs_errors) * 100:.1f}% èª¤å·® < 2%

âœ… æ–°å¢ç‰¹å¾µ:
   - No_KO_Flag: Non-call == Tenor çš„æƒ…æ³
   - Non-call Periods ç›¸é—œç‰¹å¾µ
""")

print("=" * 80)
print("æ¨¡å‹è¨“ç·´å®Œæˆï¼")
print("=" * 80)
