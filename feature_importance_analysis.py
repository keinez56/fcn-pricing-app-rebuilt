"""
FCN æ¨¡å‹ç‰¹å¾µé‡è¦æ€§æ·±å…¥åˆ†æ
"""

import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

print("=" * 80)
print("FCN æ¨¡å‹ç‰¹å¾µé‡è¦æ€§åˆ†æ")
print("=" * 80)

# ============================================================================
# 1. è¼‰å…¥æ¨¡å‹å’Œè³‡æ–™
# ============================================================================
print("\n" + "=" * 80)
print("1. è¼‰å…¥æ¨¡å‹å’Œè³‡æ–™")
print("=" * 80)

# è¼‰å…¥æ¨¡å‹
model = joblib.load('fcn_model_histgradient_boosting_deep.pkl')
print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")

# è¼‰å…¥ç‰¹å¾µåˆ—è¡¨
with open('model_features.txt', 'r') as f:
    feature_cols = [line.strip() for line in f.readlines()]
print(f"âœ… ç‰¹å¾µæ•¸é‡: {len(feature_cols)}")

# è¼‰å…¥è³‡æ–™
df = pd.read_excel('FCN_features_v3_sorted.xlsx')
X = df[feature_cols]
y = df['Coupon']
print(f"âœ… è³‡æ–™è¼‰å…¥: {X.shape}")

# ============================================================================
# 2. è¨ˆç®—Permutation Importance (æ›´æº–ç¢ºçš„ç‰¹å¾µé‡è¦æ€§)
# ============================================================================
print("\n" + "=" * 80)
print("2. Permutation Importance åˆ†æ")
print("=" * 80)

from sklearn.inspection import permutation_importance
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nè¨ˆç®—Permutation Importance (é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜)...")
perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)

# æ•´ç†çµæœ
perm_importance_df = pd.DataFrame({
    'feature': feature_cols,
    'importance_mean': perm_importance.importances_mean,
    'importance_std': perm_importance.importances_std
}).sort_values('importance_mean', ascending=False)

print("\nã€Permutation Importance Top 30ã€‘")
print(f"{'æ’å':<5} {'ç‰¹å¾µåç¨±':<40} {'é‡è¦æ€§':>12} {'æ¨™æº–å·®':>10}")
print("-" * 70)

for i, row in perm_importance_df.head(30).iterrows():
    rank = perm_importance_df.index.get_loc(i) + 1
    print(f"{rank:<5} {row['feature']:<40} {row['importance_mean']:>12.6f} {row['importance_std']:>10.6f}")

# ============================================================================
# 3. ç‰¹å¾µåˆ†é¡åˆ†æ
# ============================================================================
print("\n" + "=" * 80)
print("3. ç‰¹å¾µåˆ†é¡é‡è¦æ€§åˆ†æ")
print("=" * 80)

# å®šç¾©ç‰¹å¾µåˆ†é¡
feature_categories = {
    'FCNçµæ§‹ç‰¹å¾µ': [
        'Strike (%)', 'KO Barrier (%)', 'KI Barrier (%)', 'Tenor (m)',
        'Non-call Periods (m)', 'Cost (%)', 'Barrier_Type_AKI'
    ],
    'è²»ç”¨ç‰¹å¾µ': [
        'Fee', 'Annualized_Fee'
    ],
    'æ™‚é–“ç‰¹å¾µ': [
        'Tenor_Sqrt', 'Tenor_Squared', 'Callable_Period', 'Callable_Ratio', 'NonCall_Ratio'
    ],
    'éšœç¤™åƒ¹è¡ç”Ÿç‰¹å¾µ': [
        'KO_Strike_Distance', 'Strike_KI_Distance', 'KO_KI_Range',
        'KI_Strike_Ratio', 'KO_Strike_Ratio', 'KI_Distance_Pct', 'KO_Distance_Pct',
        'KI_Distance_Std', 'KO_Distance_Std', 'KI_Distance_Std_Sorted'
    ],
    'Basketç‰¹å¾µ': [
        'Basket_Size', 'Num_Underlyings', 'Basket_Complexity_Factor',
        'Basket_IV_Range', 'Basket_Avg_Corr', 'Basket_Min_Corr',
        'Max_Correlation', 'Min_Correlation'
    ],
    'æ’åºIVç‰¹å¾µ (Rank_1)': [
        'PUT_IMP_VOL_3M_Rank_1', 'VOLATILITY_90D_Rank_1', 'CALL_IMP_VOL_2M_25D_Rank_1',
        'PUT_IMP_VOL_2M_25D_Rank_1', 'HIST_PUT_IMP_VOL_Rank_1', 'VOL_STDDEV_Rank_1',
        'VOL_PERCENTILE_Rank_1', 'CHG_PCT_1YR_Rank_1', 'CORR_COEF_Rank_1',
        'DIVIDEND_YIELD_Rank_1', 'PX_LAST_Rank_1'
    ],
    'æ’åºIVç‰¹å¾µ (Rank_2)': [
        'PUT_IMP_VOL_3M_Rank_2', 'VOLATILITY_90D_Rank_2', 'CALL_IMP_VOL_2M_25D_Rank_2',
        'PUT_IMP_VOL_2M_25D_Rank_2', 'HIST_PUT_IMP_VOL_Rank_2', 'VOL_STDDEV_Rank_2',
        'VOL_PERCENTILE_Rank_2', 'CHG_PCT_1YR_Rank_2', 'CORR_COEF_Rank_2',
        'DIVIDEND_YIELD_Rank_2', 'PX_LAST_Rank_2'
    ],
    'æ’åºIVç‰¹å¾µ (Rank_3)': [
        'PUT_IMP_VOL_3M_Rank_3', 'VOLATILITY_90D_Rank_3', 'CALL_IMP_VOL_2M_25D_Rank_3',
        'PUT_IMP_VOL_2M_25D_Rank_3', 'HIST_PUT_IMP_VOL_Rank_3', 'VOL_STDDEV_Rank_3',
        'VOL_PERCENTILE_Rank_3', 'CHG_PCT_1YR_Rank_3', 'CORR_COEF_Rank_3',
        'DIVIDEND_YIELD_Rank_3', 'PX_LAST_Rank_3'
    ],
    'IVæ›²é¢ç‰¹å¾µ': [
        'IV_Skew_Rank_1', 'IV_Skew_Rank_2', 'IV_Skew_Rank_3',
        'Basket_Avg_Skew', 'Basket_Max_Skew',
        'IV_Premium_Rank_1', 'IV_Premium_Rank_2', 'IV_Premium_Rank_3',
        'Basket_Avg_IV_Premium', 'Basket_Max_IV_Premium', 'IV_HV_Ratio', 'IV_Spread'
    ],
    'é¢¨éšªè©•åˆ†ç‰¹å¾µ': [
        'KI_Risk_Score', 'Basket_Risk_Score', 'Risk_Score_Sorted',
        'Annualized_Vol', 'Annualized_Vol_Factor', 'Corr_Adjusted_IV', 'Return_Potential'
    ]
}

# è¨ˆç®—æ¯å€‹é¡åˆ¥çš„ç¸½é‡è¦æ€§
category_importance = {}
for category, features in feature_categories.items():
    valid_features = [f for f in features if f in perm_importance_df['feature'].values]
    if valid_features:
        importance = perm_importance_df[perm_importance_df['feature'].isin(valid_features)]['importance_mean'].sum()
        category_importance[category] = importance

# æ’åº
category_importance = dict(sorted(category_importance.items(), key=lambda x: x[1], reverse=True))

print("\nã€å„é¡åˆ¥ç‰¹å¾µé‡è¦æ€§ã€‘")
print(f"{'é¡åˆ¥':<30} {'ç¸½é‡è¦æ€§':>15} {'ä½”æ¯”':>10}")
print("-" * 60)

total_importance = sum(category_importance.values())
for category, importance in category_importance.items():
    pct = importance / total_importance * 100
    print(f"{category:<30} {importance:>15.6f} {pct:>9.2f}%")

# ============================================================================
# 4. Rank_1 vs Rank_2 vs Rank_3 é‡è¦æ€§æ¯”è¼ƒ
# ============================================================================
print("\n" + "=" * 80)
print("4. IVæ’åºé‡è¦æ€§é©—è­‰ (Rank_1 vs Rank_2 vs Rank_3)")
print("=" * 80)

rank_comparison = {
    'Rank_1': [],
    'Rank_2': [],
    'Rank_3': []
}

# æ”¶é›†å„Rankçš„é‡è¦æ€§
for _, row in perm_importance_df.iterrows():
    feature = row['feature']
    importance = row['importance_mean']

    if '_Rank_1' in feature:
        rank_comparison['Rank_1'].append(importance)
    elif '_Rank_2' in feature:
        rank_comparison['Rank_2'].append(importance)
    elif '_Rank_3' in feature:
        rank_comparison['Rank_3'].append(importance)

print("\nã€å„Rankç¸½é‡è¦æ€§ã€‘")
for rank, importances in rank_comparison.items():
    total = sum(importances)
    print(f"  {rank}: {total:.6f}")

rank_1_total = sum(rank_comparison['Rank_1'])
rank_2_total = sum(rank_comparison['Rank_2'])
rank_3_total = sum(rank_comparison['Rank_3'])

print(f"\nã€é‡è¦æ€§æ¯”ä¾‹ã€‘")
print(f"  Rank_1 / Rank_2 = {rank_1_total / rank_2_total:.2f}x")
print(f"  Rank_1 / Rank_3 = {rank_1_total / rank_3_total:.2f}x")
print(f"  Rank_2 / Rank_3 = {rank_2_total / rank_3_total:.2f}x")

print("\nâœ… é€™è­‰å¯¦äº† Worst-of çµæ§‹çš„é‡‘èé‚è¼¯ï¼š")
print("   æœ€å±éšªçš„æ¨™çš„ (Rank_1) çš„é‡è¦æ€§é é«˜æ–¼å…¶ä»–æ¨™çš„ï¼")

# ============================================================================
# 5. ç‰¹å®šIVç‰¹å¾µçš„Rankæ¯”è¼ƒ
# ============================================================================
print("\n" + "=" * 80)
print("5. ç‰¹å®šIVç‰¹å¾µçš„Ranké‡è¦æ€§æ¯”è¼ƒ")
print("=" * 80)

iv_features_to_compare = ['PUT_IMP_VOL_3M', 'VOLATILITY_90D', 'VOL_STDDEV']

for base_feature in iv_features_to_compare:
    print(f"\nã€{base_feature}ã€‘")
    for rank in ['1', '2', '3']:
        feature_name = f'{base_feature}_Rank_{rank}'
        if feature_name in perm_importance_df['feature'].values:
            importance = perm_importance_df[perm_importance_df['feature'] == feature_name]['importance_mean'].values[0]
            print(f"  Rank_{rank}: {importance:.6f}")

# ============================================================================
# 6. é—œéµç™¼ç¾ç¸½çµ
# ============================================================================
print("\n" + "=" * 80)
print("6. é—œéµç™¼ç¾ç¸½çµ")
print("=" * 80)

# Top 10 æœ€é‡è¦ç‰¹å¾µ
top_10 = perm_importance_df.head(10)

print("\nğŸ† ã€Top 10 æœ€é‡è¦ç‰¹å¾µã€‘")
print(f"{'æ’å':<5} {'ç‰¹å¾µ':<40} {'é‡è¦æ€§':>12}")
print("-" * 60)
for i, (_, row) in enumerate(top_10.iterrows(), 1):
    print(f"{i:<5} {row['feature']:<40} {row['importance_mean']:>12.6f}")

# å„²å­˜ç‰¹å¾µé‡è¦æ€§
perm_importance_df.to_excel('feature_importance_permutation.xlsx', index=False)
print("\nâœ… Permutation Importance å·²å„²å­˜è‡³: feature_importance_permutation.xlsx")

# ============================================================================
# 7. è¦–è¦ºåŒ–
# ============================================================================
print("\n" + "=" * 80)
print("7. ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨")
print("=" * 80)

# åœ–1: Top 25 ç‰¹å¾µé‡è¦æ€§
fig, ax = plt.subplots(figsize=(12, 10))
top_25 = perm_importance_df.head(25)
y_pos = np.arange(len(top_25))

ax.barh(y_pos, top_25['importance_mean'], xerr=top_25['importance_std'], align='center', color='steelblue', alpha=0.8)
ax.set_yticks(y_pos)
ax.set_yticklabels(top_25['feature'])
ax.invert_yaxis()
ax.set_xlabel('Permutation Importance')
ax.set_title('FCN Model - Top 25 Feature Importance')
plt.tight_layout()
plt.savefig('feature_importance_top25.png', dpi=150, bbox_inches='tight')
print("âœ… å·²å„²å­˜: feature_importance_top25.png")

# åœ–2: é¡åˆ¥é‡è¦æ€§
fig, ax = plt.subplots(figsize=(10, 6))
categories = list(category_importance.keys())
importances = list(category_importance.values())

colors = plt.cm.Set3(np.linspace(0, 1, len(categories)))
bars = ax.barh(categories, importances, color=colors)
ax.set_xlabel('Total Importance')
ax.set_title('Feature Category Importance')
ax.invert_yaxis()
plt.tight_layout()
plt.savefig('feature_importance_categories.png', dpi=150, bbox_inches='tight')
print("âœ… å·²å„²å­˜: feature_importance_categories.png")

# åœ–3: Rankæ¯”è¼ƒ
fig, ax = plt.subplots(figsize=(8, 5))
ranks = ['Rank_1\n(æœ€å±éšª)', 'Rank_2\n(æ¬¡å±éšª)', 'Rank_3\n(æœ€å®‰å…¨)']
rank_values = [rank_1_total, rank_2_total, rank_3_total]
colors = ['#e74c3c', '#f39c12', '#27ae60']

bars = ax.bar(ranks, rank_values, color=colors)
ax.set_ylabel('Total Importance')
ax.set_title('IV Rank Importance Comparison\n(é©—è­‰ Worst-of çµæ§‹)')

# æ·»åŠ æ•¸å€¼æ¨™ç±¤
for bar, val in zip(bars, rank_values):
    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
            f'{val:.4f}', ha='center', va='bottom', fontsize=11)

plt.tight_layout()
plt.savefig('feature_importance_rank_comparison.png', dpi=150, bbox_inches='tight')
print("âœ… å·²å„²å­˜: feature_importance_rank_comparison.png")

plt.close('all')

print("\n" + "=" * 80)
print("ç‰¹å¾µé‡è¦æ€§åˆ†æå®Œæˆï¼")
print("=" * 80)

print("""
ğŸ“Š åˆ†æçµæœæ‘˜è¦ï¼š

1. ã€çµæ§‹ç‰¹å¾µã€‘ä»ç„¶æ˜¯æœ€é‡è¦çš„ï¼Œç‰¹åˆ¥æ˜¯ KI Barrier å’Œ Strike
2. ã€IV Rank_1ã€‘çš„é‡è¦æ€§é é«˜æ–¼ Rank_2 å’Œ Rank_3ï¼Œé©—è­‰äº† Worst-of é‚è¼¯
3. ã€æ’åºIVç‰¹å¾µã€‘æ•´é«”è²¢ç»é¡¯è‘—ï¼Œè­‰æ˜äº† IV é™å†ªæ’åºçš„åƒ¹å€¼
4. ã€é¢¨éšªè©•åˆ†ç‰¹å¾µã€‘(Risk_Score_Sorted) é«˜åº¦ç›¸é—œï¼Œä½†å¯èƒ½èˆ‡å…¶ä»–ç‰¹å¾µæœ‰å†—é¤˜

é€™äº›ç™¼ç¾å®Œå…¨ç¬¦åˆ FCN çš„é‡‘èå®šåƒ¹é‚è¼¯ï¼
""")
